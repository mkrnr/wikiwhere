'''
Created on 22.01.2016

@author: Florian, Martin Koerner <info@mkoerner.de>
'''
import tldextract
import re
import argparse

if __name__ == '__main__':


    # generate help text for arguments
    parser = argparse.ArgumentParser(description='Extracts domains from a file containing the URLs of Wikipedia articles.')
    parser.add_argument('input',
                       help='a file path to the output file generated by this program')
    parser.add_argument("--output", dest="output", metavar='output path', type=str)
    args = parser.parse_args()

    inputfile_path=args.input
    outputfile_path=args.output

    tldfile = open (inputfile_path,'rb')
    tldout = open (outputfile_path,"wb") 

    lc = sum(1 for line in open(inputfile_path,'rb'))#count lines for loop

    i=0 #initial index
    while (i<lc):   
        tldline = tldfile.readline()
        results = re.split(r'\t+', tldline) #split at tab using regular expression
        for l in range(len(results)):
            if (l < 3): #first three split parts article name & numbers
                tldout.write(results[l])  
                tldout.write("\n")
            else:
                #print(tldextract.extract(results[l])) #for control
                tldout.write(str(tldextract.extract(results[l]))) #cast to string ExtractResult object
                tldout.write("\n")
        i+=1 #increase index
    tldout.close()
    tldfile.close()