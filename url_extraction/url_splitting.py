'''
Created on 22.01.2016

@author: Florian, Martin Koerner <info@mkoerner.de>
'''
import tldextract
import re
import argparse
import json

import logging

# silence error messages of tldextract about permission rights for writing a caching file
logging.basicConfig()
logging.getLogger("tldextract").setLevel(logging.CRITICAL)

# generate help text for arguments
parser = argparse.ArgumentParser(description='Extracts domains from a file containing the URLs of Wikipedia articles.')
parser.add_argument('input',
                   help='a file path to the output file generated by this program')
parser.add_argument("--output", dest="output", metavar='output path', type=str)
args = parser.parse_args()

inputfile_path=args.input
outputfile_path=args.output

tldfile = open (inputfile_path,'rb')

lc = sum(1 for line in open(inputfile_path,'rb'))#count lines for loop

i=0 #initial index
while (i<lc):   
    tldline = tldfile.readline()
    results = re.split(r'\t+', tldline) #split at tab using regular expression
    for l in range(len(results)):
        if (l < 3): #first three split parts article name & numbers
            print results[l]
        else:
            print str(tldextract.extract(results[l]))
            print 
    i+=1 #increase index
tldfile.close()

# write dictionary with key = Wikipedia article and value = URLs to JSON file
#with open(outputfile_path, 'w') as f:
#    json.dump(article_link_dictionary, f, indent=4, sort_keys=True)
#    print "JSON file was stored successfully"
