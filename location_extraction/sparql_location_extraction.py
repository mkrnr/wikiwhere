'''
Created on Jan 11, 2016

@author: Martin Koerner <info@mkoerner.de>
'''

from SPARQLWrapper import SPARQLWrapper, JSON
from SPARQLWrapper.SPARQLExceptions import QueryBadFormed

from urlparse import urlparse
import json 
import argparse
from utils import dbpedia_mapping, majority_voting
import urllib2
import socket
import re

# generate help text for arguments
parser = argparse.ArgumentParser(description='Extracts Websites with locations from dbpedia.')
parser.add_argument('output',
                   help='a file path to the output file generated by this program')
parser.add_argument("--language", dest="language", type=str, help="one of the language editions of dbpedia (default: en)", required=True)
parser.add_argument("--threshold", dest="threshold", default=0.1, type=float, help="absolute threshold for majority voting on coordinates (default: 0.1)" )

args = parser.parse_args()

outputfile_path=args.output
sparql_language=args.language
absolute_threshold=args.threshold

print "running sparql_location_extraction" 

# get mapping from two-letter country code to dbpedia endpoint URL
dbpedia_url = dbpedia_mapping.language_to_dbpedia_url(sparql_language) 

print "Running on the following dbpedia SPARQL endpoint: " + dbpedia_url

sparql = SPARQLWrapper(dbpedia_url)
# sparql = SPARQLWrapper("https://query.wikidata.org/sparql")
# sparql = SPARQLWrapper("https://query.wikidata.org/bigdata/namespace/wdq/sparql")

sparql.setTimeout(1000)


# SPARQL query that 
namespaces = """
PREFIX dbo: <http://dbpedia.org/resource/classes#>
PREFIX dbp: <http://dbpedia.org/property/>
"""

location_query = """
{
    SELECT * WHERE {
        ?match dbo:locationCity ?locationCity .
        ?locationCity dbp:latitude ?lat .
        ?locationCity dbp:longitude ?long
    }
}
UNION
{
    SELECT * WHERE {
        ?match dbo:locationCity ?locationCity .
        ?locationCity geo:lat ?lat .
        ?locationCity geo:long ?long
    }
}
UNION
{
    SELECT * WHERE {
        ?match dbp:parentAgency ?parentAgency .
        ?parentAgency geo:lat ?lat .
        ?parentAgency geo:long ?long
    }
}
UNION
{
    SELECT * WHERE {
        ?match geo:lat ?lat .
        ?match geo:long ?long
    }
}
UNION
{
    SELECT * WHERE {
        ?match dbo:location ?location .
        ?location geo:lat ?lat .
        ?location geo:long ?long
    }
}
"""
query_string = namespaces + """
SELECT * WHERE {
    {
        SELECT * WHERE {
            ?match foaf:homepage  ?url .
            """ + location_query + """
        }
    }
    UNION
    {
        SELECT * WHERE {
            ?match dbp:url  ?url .
            """ + location_query + """
        }
    }
}
"""

match_count = 0
domain_matches = {}

#limit = 5000
limit = 500
offset = 0

url_location_dictionary={}

while True:
    print offset
    query_string_with_offset = query_string + " LIMIT " + str(limit) + " OFFSET " + str(offset)

    sparql.setQuery(query_string_with_offset)
    sparql.setReturnFormat(JSON)
    try:
        results = sparql.query().convert()
    except QueryBadFormed:
        print "SPARQL query bad formed: " + query_string_with_offset
    except urllib2.HTTPError:
        print "HTTP Error 502"
    except urllib2.URLError:
        print "Network is unreachable"
    except socket.timeout:
        print "Query timed out"
    
    
    if len(results["results"]["bindings"]) > 0:
        for result in results["results"]["bindings"]:
            url=result["url"]["value"]

            try:
                # fix web.archive.org URLs
                if str(url).startswith("https://web.archive.org"):

                    url = re.sub(r'https://web.archive.org/web/[0-9]+/','',url)

                    # check if still web.archive.org link or not starting as a URL 
                    if str(url).startswith("https://web.archive.org") or not str(url).startswith("http"):
                        continue

            except UnicodeEncodeError:
                continue
            parsed_url = urlparse(url.encode("utf8"))
            stripped_url = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_url)

            location_tuple=(float(result["lat"]["value"]),float(result["long"]["value"]))
            if url_location_dictionary.has_key(stripped_url) :
                url_location_dictionary[stripped_url].append(location_tuple)
            else:
                locations = []
                locations.append(location_tuple)
                url_location_dictionary[stripped_url] = locations
                
        offset += limit
    else:
        break
    

# do a majority voting on the retrieved locations
url_majority_location_dictionary = {}
for url in url_location_dictionary:
    # skip web.archive.org links
    if str(url).startswith("https://web.archive.org"):
        continue
    url_majority_location_dictionary[url]=majority_voting.vote(url_location_dictionary[url],absolute_threshold)

# write results to a JSON file
with open(outputfile_path, 'w') as f:
    json.dump(url_majority_location_dictionary, f, indent=4, sort_keys=True)
    print "File was stored successfully"
